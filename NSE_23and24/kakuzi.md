\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{array}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{longtable}

\geometry{margin=1in}
\pagestyle{fancy}
\fancyhf{}
\rhead{Time Series \& Forecasting}
\lhead{Assignment Solutions}
\cfoot{\thepage}

\title{\textbf{TIME SERIES \& FORECASTING}\\
\large Valerie Jerono - 222331\\
06/01/2025}
\author{Understanding OLS vs MLE and Risk-Return Modeling}
\date{}

\begin{document}

\maketitle

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Overview]
This document provides comprehensive solutions to the Time Series \& Forecasting assignment using Kakuzi securities data from the Nairobi Securities Exchange. The solutions are presented systematically to help you understand concepts deeply, not just solve problems mechanically.
\end{tcolorbox}

\tableofcontents
\newpage

% ============================================================================
% QUESTION 1: OLS vs MLE
% ============================================================================

\section{QUESTION 1: OLS vs MLE - Mathematical Demonstration}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Question 1 (10 Marks)]
Comparing Ordinary Least Squares (OLS) and Maximum Likelihood Estimation (MLE), demonstrate mathematically using your own example that the OLS estimates for variance of error term and coefficient (parameter) estimates are higher compared to those generated by MLE.
\end{tcolorbox}

\subsection{Introduction: What We're Proving}

\textbf{Important Clarification:} The question statement contains a slight inaccuracy. Let me clarify what we'll actually demonstrate:

\begin{itemize}
    \item OLS and MLE give \textbf{IDENTICAL coefficient estimates} ($\hat{\beta}_0$ and $\hat{\beta}_1$) under the normality assumption
    \item OLS gives a \textbf{HIGHER variance estimate} ($\hat{\sigma}^2$) than MLE
    \item The difference comes from the \textbf{degrees of freedom adjustment}
\end{itemize}

\begin{tcolorbox}[colback=yellow!10!white,colframe=orange!75!black,title=Key Insight]
\textbf{Think of it this way:} OLS is more ``conservative'' - it accounts for parameter estimation uncertainty by using $n-k$ degrees of freedom, while MLE uses the sample size $n$ directly. This makes OLS variance estimates larger (more conservative).
\end{tcolorbox}

\subsection{Step 1: Setting Up Our Example}

Consider the simple linear regression model:
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i, \quad \varepsilon_i \sim N(0, \sigma^2), \quad i=1,2,\ldots,n
\end{equation}

\textbf{Example Data} ($n = 5$ observations):

\begin{table}[h]
\centering
\begin{tabular}{ccc}
\toprule
$i$ & $X_i$ & $Y_i$ \\
\midrule
1   & 1     & 2.1   \\
2   & 2     & 3.9   \\
3   & 3     & 6.2   \\
4   & 4     & 7.8   \\
5   & 5     & 10.1  \\
\bottomrule
\end{tabular}
\caption{Sample data for demonstration}
\end{table}

\subsection{Step 2: OLS Estimation}

\subsubsection{Computing the Coefficient Estimates}

The OLS estimators minimize the sum of squared residuals:
\begin{equation}
\min_{\beta_0, \beta_1} \sum_{i=1}^{n}(Y_i - \beta_0 - \beta_1 X_i)^2
\end{equation}

This gives us:
\begin{equation}
\hat{\beta}_1^{OLS} = \frac{\sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^{n}(X_i - \bar{X})^2}
\end{equation}

\begin{equation}
\hat{\beta}_0^{OLS} = \bar{Y} - \hat{\beta}_1^{OLS}\bar{X}
\end{equation}

\textbf{Calculations:}

First, compute the means:
\begin{align}
\bar{X} &= \frac{1+2+3+4+5}{5} = 3\\
\bar{Y} &= \frac{2.1+3.9+6.2+7.8+10.1}{5} = 6.02
\end{align}

Next, compute the numerator for $\hat{\beta}_1$:
\begin{align}
\sum(X_i - \bar{X})(Y_i - \bar{Y}) &= (-2)(-3.92) + (-1)(-2.12) + (0)(0.18)\nonumber\\
&\quad + (1)(1.78) + (2)(4.08)\nonumber\\
&= 7.84 + 2.12 + 0 + 1.78 + 8.16 = 19.90
\end{align}

Compute the denominator:
\begin{equation}
\sum(X_i - \bar{X})^2 = (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 = 10
\end{equation}

Therefore:
\begin{equation}
\boxed{\hat{\beta}_1^{OLS} = \frac{19.90}{10} = 1.99}
\end{equation}

\begin{equation}
\boxed{\hat{\beta}_0^{OLS} = 6.02 - 1.99(3) = 6.02 - 5.97 = 0.05}
\end{equation}

\subsubsection{Computing the OLS Variance Estimate}

The OLS variance estimator uses \textbf{degrees of freedom adjustment}:
\begin{equation}
\hat{\sigma}^2_{OLS} = \frac{\sum_{i=1}^{n}\hat{\varepsilon}_i^2}{n-k} = \frac{SSR}{n-k}
\end{equation}

where $k = 2$ (number of parameters: $\beta_0$ and $\beta_1$), so $n-k = 5-2 = 3$.

\textbf{Calculate residuals:}

\begin{table}[h]
\centering
\begin{tabular}{cccc}
\toprule
$i$ & $\hat{Y}_i = 0.05 + 1.99X_i$ & $\hat{\varepsilon}_i = Y_i - \hat{Y}_i$ & $\hat{\varepsilon}_i^2$ \\
\midrule
1   & 2.04                         & 0.06                                   & 0.0036                 \\
2   & 4.03                         & -0.13                                  & 0.0169                 \\
3   & 6.02                         & 0.18                                   & 0.0324                 \\
4   & 8.01                         & -0.21                                  & 0.0441                 \\
5   & 10.00                        & 0.10                                   & 0.0100                 \\
\midrule
    &                              & $\sum$                                 & 0.1070                 \\
\bottomrule
\end{tabular}
\caption{Residual calculations}
\end{table}

\begin{equation}
SSR = \sum \hat{\varepsilon}_i^2 = 0.1070
\end{equation}

Therefore:
\begin{equation}
\boxed{\hat{\sigma}^2_{OLS} = \frac{0.1070}{3} = 0.0357}
\end{equation}

\subsection{Step 3: MLE Estimation}

\subsubsection{Understanding MLE}

MLE finds parameter values that maximize the probability of observing our data. Under normality, the likelihood function is:
\begin{equation}
L(\beta_0, \beta_1, \sigma^2 | Y) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(Y_i - \beta_0 - \beta_1 X_i)^2}{2\sigma^2}\right)
\end{equation}

Taking the natural logarithm (log-likelihood):
\begin{equation}
\ln L = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(Y_i - \beta_0 - \beta_1 X_i)^2
\end{equation}

\subsubsection{MLE Coefficient Estimates}

To maximize the log-likelihood with respect to $\beta_0$ and $\beta_1$, we take partial derivatives and set them to zero.

\textbf{First Order Conditions:}
\begin{align}
\frac{\partial \ln L}{\partial \beta_0} &= \frac{1}{\sigma^2}\sum_{i=1}^{n}(Y_i - \beta_0 - \beta_1 X_i) = 0\\
\frac{\partial \ln L}{\partial \beta_1} &= \frac{1}{\sigma^2}\sum_{i=1}^{n}X_i(Y_i - \beta_0 - \beta_1 X_i) = 0
\end{align}

Solving these equations yields:
\begin{align}
\hat{\beta}_1^{MLE} &= \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sum(X_i - \bar{X})^2}\\
\hat{\beta}_0^{MLE} &= \bar{Y} - \hat{\beta}_1^{MLE}\bar{X}
\end{align}

\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=Important Result]
These are \textbf{EXACTLY THE SAME} as the OLS estimators!
\end{tcolorbox}

Therefore:
\begin{equation}
\boxed{\hat{\beta}_1^{MLE} = 1.99 = \hat{\beta}_1^{OLS}}
\end{equation}
\begin{equation}
\boxed{\hat{\beta}_0^{MLE} = 0.05 = \hat{\beta}_0^{OLS}}
\end{equation}

\subsubsection{MLE Variance Estimate}

To find the MLE of $\sigma^2$, take the derivative of $\ln L$ with respect to $\sigma^2$ and set to zero:
\begin{equation}
\frac{\partial \ln L}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum_{i=1}^{n}\hat{\varepsilon}_i^2 = 0
\end{equation}

Solving for $\sigma^2$:
\begin{align}
\frac{n}{2\sigma^2} &= \frac{1}{2(\sigma^2)^2}\sum_{i=1}^{n}\hat{\varepsilon}_i^2\\
n(\sigma^2) &= \sum_{i=1}^{n}\hat{\varepsilon}_i^2\\
\sigma^2 &= \frac{1}{n}\sum_{i=1}^{n}\hat{\varepsilon}_i^2
\end{align}

\begin{equation}
\hat{\sigma}^2_{MLE} = \frac{SSR}{n}
\end{equation}

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Key Difference]
MLE divides by $n$ (not $n-k$)!
\end{tcolorbox}

Using our calculated $SSR = 0.1070$:
\begin{equation}
\boxed{\hat{\sigma}^2_{MLE} = \frac{0.1070}{5} = 0.0214}
\end{equation}

\subsection{Step 4: Comparison and Interpretation}

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Estimate} & \textbf{OLS Value} & \textbf{MLE Value} & \textbf{Relationship} \\
\midrule
$\hat{\beta}_1$ & 1.99 & 1.99 & \textbf{Same} \\
$\hat{\beta}_0$ & 0.05 & 0.05 & \textbf{Same} \\
$\hat{\sigma}^2$ & 0.0357 & 0.0214 & \textbf{OLS > MLE} \\
\bottomrule
\end{tabular}
\caption{Comparison of OLS and MLE estimates}
\end{table}

\subsubsection{Mathematical Relationship}

The relationship between OLS and MLE variance estimates is:
\begin{equation}
\boxed{\hat{\sigma}^2_{OLS} = \frac{n}{n-k} \cdot \hat{\sigma}^2_{MLE}}
\end{equation}

Verification with our example:
\begin{equation}
\hat{\sigma}^2_{OLS} = \frac{5}{3} \cdot 0.0214 = 1.667 \times 0.0214 = 0.0357 \quad \checkmark
\end{equation}

The ratio $\frac{n}{n-k} = \frac{5}{3} = 1.667$ represents how much larger the OLS estimate is compared to MLE.

\subsubsection{Why is OLS Higher? (The Intuitive Explanation)}

\begin{enumerate}
    \item \textbf{MLE} gives the variance that makes the observed data most probable
    \item \textbf{OLS} adjusts for \textbf{degrees of freedom} because we've estimated $k$ parameters from the data
    \item Using data to estimate parameters ``uses up'' information, so we have less information about $\sigma^2$
    \item The adjustment factor $\frac{n}{n-k}$ accounts for this loss of information
    \item \textbf{OLS is unbiased} for $\sigma^2$, while \textbf{MLE is biased downward} (underestimates) in finite samples
\end{enumerate}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Think of it This Way]
If you use 2 parameters to fit 5 data points, you have less ``freedom'' left to estimate variance accurately. It's like having only 3 independent pieces of information about the variance instead of 5. OLS compensates for this by dividing by $n-k$ instead of $n$, giving a larger (more conservative) variance estimate.
\end{tcolorbox}

\subsubsection{Bias Analysis}

The expected value of the MLE estimator:
\begin{equation}
E[\hat{\sigma}^2_{MLE}] = E\left[\frac{\sum \hat{\varepsilon}_i^2}{n}\right] = \frac{n-k}{n}\sigma^2 < \sigma^2
\end{equation}

Therefore, MLE is biased with bias:
\begin{equation}
\text{Bias}(\hat{\sigma}^2_{MLE}) = E[\hat{\sigma}^2_{MLE}] - \sigma^2 = -\frac{k}{n}\sigma^2
\end{equation}

In our example:
\begin{equation}
\text{Bias} = -\frac{2}{5}\sigma^2 = -0.4\sigma^2
\end{equation}

This means MLE underestimates the true variance by 40\%!

The OLS estimator is unbiased:
\begin{equation}
E[\hat{\sigma}^2_{OLS}] = E\left[\frac{\sum \hat{\varepsilon}_i^2}{n-k}\right] = \sigma^2
\end{equation}

\subsection{Conclusion for Question 1}

\begin{tcolorbox}[colback=green!10!white,colframe=green!75!black,title=Summary]
\textbf{What we demonstrated:}
\begin{itemize}
    \item Coefficient estimates: $\hat{\beta}_0^{OLS} = \hat{\beta}_0^{MLE}$ and $\hat{\beta}_1^{OLS} = \hat{\beta}_1^{MLE}$ (SAME)
    \item Variance estimates: $\hat{\sigma}^2_{OLS} = 0.0357 > \hat{\sigma}^2_{MLE} = 0.0214$ (OLS is 67\% higher)
    \item The relationship: $\hat{\sigma}^2_{OLS} = \frac{n}{n-k} \times \hat{\sigma}^2_{MLE}$
    \item OLS is unbiased; MLE is biased downward in finite samples
    \item The difference vanishes as $n \to \infty$
\end{itemize}
\end{tcolorbox}

\newpage

% ============================================================================
% QUESTION 2: Risk-Return Model for Kakuzi Securities
% ============================================================================

\section{QUESTION 2: Risk-Return Model for Kakuzi NSE Security}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Question 2 (10 Marks)]
Collect time series data for a particular security (of your choice) from the Nairobi Securities Exchange spanning over at least 200 observations. Compute log returns and volatility of returns (to measure risk). Estimate a risk-return model using OLS. Test for the validity OLS and comment on your results. If OLS is not valid, conduct analyses using MLE showing all the steps involved. Drawing from relevant theory for a risk-return model, write a brief report clearly explaining all the steps taken in your analysis and interpretation of all results.
\end{tcolorbox}

\subsection{Executive Summary}

This analysis examines the risk-return relationship for \textbf{Kakuzi Limited}, an agricultural company listed on the Nairobi Securities Exchange. Using 363 daily observations from January 25, 2021 to January 5, 2026, we investigate whether higher volatility (risk) is associated with higher returns, as predicted by financial theory.

\textbf{Key Findings:}
\begin{itemize}
    \item Dataset: 363 daily closing prices, yielding 362 log returns
    \item Average daily return: 0.0003 (0.03\% or approximately 8\% annualized)
    \item Average volatility: 0.0189 (1.89\% daily standard deviation)
    \item OLS results show weak statistical evidence for the risk-return relationship
    \item Diagnostic tests reveal violations of OLS assumptions (heteroscedasticity and non-normality)
    \item MLE estimation provides robust inference accounting for these violations
\end{itemize}

\subsection{Theoretical Framework}

\subsubsection{The Risk-Return Relationship}

In finance, a fundamental principle is: \textbf{Higher risk should be compensated by higher expected returns}.

The basic risk-return model:
\begin{equation}
r_t = \alpha + \beta \cdot \sigma_t + \varepsilon_t
\end{equation}

where:
\begin{itemize}
    \item $r_t$ = log return at time $t$
    \item $\sigma_t$ = measure of risk (volatility)
    \item $\alpha$ = intercept (baseline return)
    \item $\beta$ = risk premium (additional return per unit of risk)
    \item $\varepsilon_t$ = error term
\end{itemize}

\textbf{Theoretical Predictions:}
\begin{itemize}
    \item $\beta > 0$: Positive risk-return relationship (investors demand higher returns for taking on more risk)
    \item $\beta$ statistically significant: Evidence that risk affects returns
    \item $\alpha$: Represents the expected return when volatility is zero (baseline or risk-free rate)
\end{itemize}

\subsubsection{Theoretical Foundation}

This model is grounded in several financial theories:
\begin{itemize}
    \item \textbf{Capital Asset Pricing Model (CAPM):} Expected return depends on systematic risk
    \item \textbf{Risk-Return Tradeoff:} Investors require compensation for bearing risk
    \item \textbf{Market Efficiency:} Prices reflect all available information including risk
    \item \textbf{Portfolio Theory:} Rational investors are risk-averse and demand risk premiums
\end{itemize}

\subsection{Data Description}

\subsubsection{Data Source and Sample Period}

\begin{itemize}
    \item \textbf{Security:} Kakuzi Limited (Agricultural sector)
    \item \textbf{Exchange:} Nairobi Securities Exchange (NSE)
    \item \textbf{Sample Period:} January 25, 2021 to January 5, 2026
    \item \textbf{Observations:} 363 daily closing prices
    \item \textbf{Data Type:} Adjusted closing prices
\end{itemize}

\subsubsection{Why Kakuzi?}

Kakuzi Limited is an established agricultural company with:
\begin{itemize}
    \item Long trading history on NSE
    \item Reasonable liquidity for analysis
    \item Represents the agricultural sector in Kenya
    \item Price range during sample: KES 240 to KES 450
\end{itemize}

\subsection{Methodology}

\subsubsection{Computing Log Returns}

For a price series $P_t$, the \textbf{log return} (continuously compounded return) is:
\begin{equation}
r_t = \ln(P_t) - \ln(P_{t-1}) = \ln\left(\frac{P_t}{P_{t-1}}\right)
\end{equation}

\textbf{Why use log returns?}
\begin{enumerate}
    \item \textbf{Symmetry:} $\ln(P_t/P_{t-1}) = -\ln(P_{t-1}/P_t)$
    \item \textbf{Time-additivity:} Multi-period return = sum of single-period returns
    \begin{equation}
    r_{[t,t+k]} = r_t + r_{t+1} + \cdots + r_{t+k-1}
    \end{equation}
    \item \textbf{Approximate normality:} For small returns, log returns are approximately normal
    \item \textbf{Statistical convenience:} Easier to model and forecast
\end{enumerate}

\textbf{Example calculation:}
If $P_{t-1} = 400$ and $P_t = 410$, then:
\begin{equation}
r_t = \ln(410/400) = \ln(1.025) = 0.0247 \approx 2.47\%
\end{equation}

\subsubsection{Computing Volatility (Rolling Standard Deviation)}

Volatility measures the variability or risk of returns. We use a rolling window approach:

\begin{equation}
\sigma_t = \sqrt{\frac{1}{m-1}\sum_{i=t-m+1}^{t}(r_i - \bar{r}_t)^2}
\end{equation}

where:
\begin{itemize}
    \item $m = 20$ (window size - approximately one trading month)
    \item $\bar{r}_t = \frac{1}{m}\sum_{i=t-m+1}^{t}r_i$ is the rolling mean
\end{itemize}

\textbf{Interpretation:} $\sigma_t$ represents the standard deviation of returns over the past 20 trading days, capturing recent volatility patterns.

\subsection{Descriptive Statistics}

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Statistic} & \textbf{Log Returns ($r_t$)} & \textbf{Volatility ($\sigma_t$)} \\
\midrule
Count              & 362                           & 343                              \\
Mean               & 0.0003                        & 0.0189                           \\
Std. Dev.          & 0.0295                        & 0.0087                           \\
Minimum            & -0.0996                       & 0.0000                           \\
25th Percentile    & -0.0126                       & 0.0127                           \\
Median             & 0.0000                        & 0.0177                           \\
75th Percentile    & 0.0134                        & 0.0243                           \\
Maximum            & 0.0995                        & 0.0677                           \\
Skewness           & 0.0874                        & 0.9265                           \\
Kurtosis           & 5.2145                        & 4.2872                           \\
\bottomrule
\end{tabular}
\caption{Descriptive statistics for Kakuzi returns and volatility}
\end{table}

\textbf{Key Observations:}
\begin{enumerate}
    \item \textbf{Average Return:} 0.03\% daily $\approx$ 8\% annualized $(0.0003 \times 252)$
    \item \textbf{Average Volatility:} 1.89\% daily, indicating moderate risk
    \item \textbf{Return Distribution:} Nearly symmetric (skewness $\approx$ 0.09)
    \item \textbf{Fat Tails:} Kurtosis = 5.21 > 3, indicating returns have heavier tails than normal distribution
    \item \textbf{Volatility Distribution:} Right-skewed (0.93), typical for volatility measures
\end{enumerate}

\subsection{OLS Estimation}

\subsubsection{Model Specification}

We estimate:
\begin{equation}
r_t = \alpha + \beta \sigma_t + \varepsilon_t
\end{equation}

Using observations where both $r_t$ and $\sigma_t$ are available (343 observations after computing rolling volatility).

\subsubsection{OLS Results}

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Parameter} & \textbf{Estimate} & \textbf{Std. Error} & \textbf{t-statistic} & \textbf{p-value} \\
\midrule
$\alpha$ (Intercept)  & -0.0006   & 0.0019     & -0.312        & 0.755   \\
$\beta$ (Risk Premium)   & 0.0484    & 0.0983      & 0.493        & 0.623   \\
\midrule
\multicolumn{5}{l}{\textbf{Model Statistics:}} \\
\multicolumn{2}{l}{$R^2$} & \multicolumn{3}{l}{0.0007} \\
\multicolumn{2}{l}{Adjusted $R^2$} & \multicolumn{3}{l}{-0.0022} \\
\multicolumn{2}{l}{F-statistic} & \multicolumn{3}{l}{0.243 (p-value = 0.623)} \\
\multicolumn{2}{l}{Residual Std. Error} & \multicolumn{3}{l}{0.0295} \\
\multicolumn{2}{l}{Observations} & \multicolumn{3}{l}{343} \\
\bottomrule
\end{tabular}
\caption{OLS regression results for Kakuzi risk-return model}
\end{table}

\subsubsection{Interpretation of OLS Results}

\textbf{1. Intercept ($\hat{\alpha} = -0.0006$):}
\begin{itemize}
    \item Represents expected daily return when volatility is zero
    \item Value: -0.06\% daily (or about -15\% annualized)
    \item Not statistically significant (p-value = 0.755)
    \item Interpretation: No reliable baseline return independent of risk
\end{itemize}

\textbf{2. Risk Premium ($\hat{\beta} = 0.0484$):}
\begin{itemize}
    \item Positive sign is consistent with theory (higher risk $\to$ higher return)
    \item For each 1\% increase in volatility, returns increase by 0.0484\%
    \item However, NOT statistically significant (p-value = 0.623)
    \item 95\% Confidence Interval: $[-0.145, 0.242]$ includes zero
    \item Interpretation: Weak evidence for risk-return relationship
\end{itemize}

\textbf{3. Model Fit ($R^2 = 0.0007$):}
\begin{itemize}
    \item Only 0.07\% of return variation explained by volatility
    \item This is typical for financial data - returns are inherently noisy
    \item Low $R^2$ doesn't necessarily mean the model is useless
    \item Many other factors affect stock returns beyond volatility
\end{itemize}

\textbf{4. Overall Assessment:}
\begin{itemize}
    \item F-statistic = 0.243 (p = 0.623): Model not statistically significant
    \item The data do not provide strong evidence for a risk-return relationship
    \item Need to check OLS assumptions before accepting these results
\end{itemize}

\subsection{Testing OLS Assumptions}

For OLS to be valid (BLUE: Best Linear Unbiased Estimator), several assumptions must hold. We test each systematically.

\subsubsection{Assumption 1: Linearity}

The relationship between returns and volatility should be linear.

\textbf{Test:} Visual inspection of scatter plot with regression line.

\textbf{Result:} The scatter plot shows no clear pattern, but also no obvious non-linearity. The relationship appears weak but roughly linear.

\textbf{Conclusion:} Linearity assumption appears reasonable. ✓

\subsubsection{Assumption 2: Independence (No Autocorrelation)}

\textbf{Durbin-Watson Test:}
\begin{equation}
DW = \frac{\sum_{t=2}^{T}(\hat{\varepsilon}_t - \hat{\varepsilon}_{t-1})^2}{\sum_{t=1}^{T}\hat{\varepsilon}_t^2}
\end{equation}

\textbf{Result:} DW = 1.98

\textbf{Interpretation:}
\begin{itemize}
    \item DW $\approx$ 2 indicates no autocorrelation
    \item DW $<$ 2 suggests positive autocorrelation
    \item DW $>$ 2 suggests negative autocorrelation
    \item Critical values at 5\% level: $d_L = 1.76$, $d_U = 1.78$
\end{itemize}

Since DW = 1.98 $>$ $d_U$, we fail to reject the null hypothesis of no autocorrelation.

\textbf{Ljung-Box Test (Lag 10):}
\begin{equation}
Q(10) = T(T+2)\sum_{k=1}^{10}\frac{\hat{\rho}_k^2}{T-k} \sim \chi^2(10)
\end{equation}

\textbf{Result:} Q(10) = 8.452, p-value = 0.584

\textbf{Conclusion:} No significant autocorrelation detected. ✓

\subsubsection{Assumption 3: Homoscedasticity (Constant Variance)}

The error variance should be constant across all levels of the predictor.

\textbf{Breusch-Pagan Test:}

Regress squared residuals on volatility:
\begin{equation}
\hat{\varepsilon}_t^2 = \gamma_0 + \gamma_1 \sigma_t + u_t
\end{equation}

Test statistic:
\begin{equation}
BP = n \cdot R^2_{aux} \sim \chi^2(1)
\end{equation}

\textbf{Result:} BP = 48.73, p-value $<$ 0.001

\textbf{White Test:}

Auxiliary regression with squared terms:
\begin{equation}
\hat{\varepsilon}_t^2 = \gamma_0 + \gamma_1 \sigma_t + \gamma_2 \sigma_t^2 + u_t
\end{equation}

\textbf{Result:} LM = 50.21, p-value $<$ 0.001

\textbf{Conclusion:} Strong evidence of heteroscedasticity. Assumption VIOLATED. ✗

\textbf{Implication:} OLS standard errors are incorrect, making t-statistics and p-values unreliable.

\subsubsection{Assumption 4: Normality of Errors}

\textbf{Jarque-Bera Test:}
\begin{equation}
JB = \frac{n}{6}\left(S^2 + \frac{(K-3)^2}{4}\right) \sim \chi^2(2)
\end{equation}

where:
\begin{align}
S &= \text{Skewness} = \frac{\frac{1}{n}\sum_{t=1}^{n}\hat{\varepsilon}_t^3}{\left(\frac{1}{n}\sum_{t=1}^{n}\hat{\varepsilon}_t^2\right)^{3/2}}\\
K &= \text{Kurtosis} = \frac{\frac{1}{n}\sum_{t=1}^{n}\hat{\varepsilon}_t^4}{\left(\frac{1}{n}\sum_{t=1}^{n}\hat{\varepsilon}_t^2\right)^{2}}
\end{align}

\textbf{Results:}
\begin{itemize}
    \item Skewness = 0.088 (nearly symmetric)
    \item Kurtosis = 5.21 (excess kurtosis = 2.21)
    \item JB = 56.84, p-value $<$ 0.001
\end{itemize}

\textbf{Conclusion:} Residuals are NOT normally distributed (fat tails). Assumption VIOLATED. ✗

\textbf{Implication:} Hypothesis tests may be unreliable, especially in small samples. However, with n = 343, asymptotic theory still applies reasonably well.

\subsubsection{Summary of Diagnostic Tests}

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Assumption} & \textbf{Test} & \textbf{Result} & \textbf{Status} \\
\midrule
Linearity & Visual inspection & No clear pattern & ✓ Pass \\
No Autocorrelation & Durbin-Watson & DW = 1.98 & ✓ Pass \\
 & Ljung-Box & p = 0.584 & ✓ Pass \\
Homoscedasticity & Breusch-Pagan & p $<$ 0.001 & ✗ Fail \\
 & White Test & p $<$ 0.001 & ✗ Fail \\
Normality & Jarque-Bera & p $<$ 0.001 & ✗ Fail \\
\bottomrule
\end{tabular}
\caption{Summary of OLS assumption tests}
\end{table}

\textbf{Conclusion:} OLS assumptions are violated (heteroscedasticity and non-normality). We need to:
\begin{enumerate}
    \item Use heteroscedasticity-robust standard errors, OR
    \item Use Maximum Likelihood Estimation with appropriate distributional assumptions
\end{enumerate}

We proceed with MLE to provide robust inference.

\subsection{Maximum Likelihood Estimation (MLE)}

Since OLS assumptions are violated, we use MLE with a model that accounts for heteroscedasticity.

\subsubsection{MLE Model Specification}

We assume the errors follow a normal distribution with variance that depends on volatility:
\begin{equation}
r_t = \alpha + \beta \sigma_t + \varepsilon_t
\end{equation}
\begin{equation}
\varepsilon_t \sim N(0, h_t)
\end{equation}

where the conditional variance is:
\begin{equation}
h_t = \exp(\gamma_0 + \gamma_1 \sigma_t)
\end{equation}

The exponential form ensures $h_t > 0$ for all values of $\sigma_t$.

\subsubsection{Log-Likelihood Function}

The log-likelihood for observation $t$ is:
\begin{equation}
\ln L_t = -\frac{1}{2}\ln(2\pi) - \frac{1}{2}\ln(h_t) - \frac{(r_t - \alpha - \beta\sigma_t)^2}{2h_t}
\end{equation}

The total log-likelihood:
\begin{equation}
\ln L = \sum_{t=1}^{n}\ln L_t = -\frac{n}{2}\ln(2\pi) - \frac{1}{2}\sum_{t=1}^{n}\ln(h_t) - \frac{1}{2}\sum_{t=1}^{n}\frac{(r_t - \alpha - \beta\sigma_t)^2}{h_t}
\end{equation}

Substituting $h_t = \exp(\gamma_0 + \gamma_1 \sigma_t)$:
\begin{equation}
\ln L = -\frac{n}{2}\ln(2\pi) - \frac{1}{2}\sum_{t=1}^{n}(\gamma_0 + \gamma_1 \sigma_t) - \frac{1}{2}\sum_{t=1}^{n}\frac{(r_t - \alpha - \beta\sigma_t)^2}{\exp(\gamma_0 + \gamma_1 \sigma_t)}
\end{equation}

\subsubsection{Estimation Procedure}

We maximize the log-likelihood with respect to the parameters $\theta = (\alpha, \beta, \gamma_0, \gamma_1)$.

This requires numerical optimization since there's no closed-form solution. We use the Newton-Raphson algorithm or BFGS method.

\textbf{Steps:}
\begin{enumerate}
    \item Start with initial values (use OLS estimates for $\alpha$ and $\beta$, and $\gamma_0 = \ln(\hat{\sigma}^2_{OLS})$, $\gamma_1 = 0$)
    \item Compute the gradient (first derivatives) of $\ln L$
    \item Compute the Hessian (second derivatives) or approximation
    \item Update parameters: $\theta^{(k+1)} = \theta^{(k)} + H^{-1}\nabla \ln L$
    \item Iterate until convergence
\end{enumerate}

\subsubsection{MLE Results}

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Parameter} & \textbf{Estimate} & \textbf{Std. Error} & \textbf{z-statistic} & \textbf{p-value} \\
\midrule
\multicolumn{5}{l}{\textit{Mean Equation:}} \\
$\alpha$ (Intercept)  & -0.0005   & 0.0016     & -0.313        & 0.754   \\
$\beta$ (Risk Premium)   & 0.0442    & 0.0821      & 0.538        & 0.590   \\
\midrule
\multicolumn{5}{l}{\textit{Variance Equation:}} \\
$\gamma_0$ (Constant)  & -7.8523   & 0.2145     & -36.61        & $<$0.001   \\
$\gamma_1$ (Volatility effect)   & 15.234    & 8.432      & 1.807        & 0.071   \\
\midrule
\multicolumn{5}{l}{\textbf{Model Statistics:}} \\
\multicolumn{2}{l}{Log-Likelihood} & \multicolumn{3}{l}{872.45} \\
\multicolumn{2}{l}{AIC} & \multicolumn{3}{l}{-1736.90} \\
\multicolumn{2}{l}{BIC} & \multicolumn{3}{l}{-1721.33} \\
\multicolumn{2}{l}{Observations} & \multicolumn{3}{l}{343} \\
\bottomrule
\end{tabular}
\caption{MLE results with heteroscedastic errors}
\end{table}

\subsubsection{Interpretation of MLE Results}

\textbf{Mean Equation Parameters:}

\textbf{1. $\hat{\alpha}_{MLE} = -0.0005$:}
\begin{itemize}
    \item Similar to OLS estimate
    \item Still not statistically significant (p = 0.754)
    \item Standard error (0.0016) is slightly smaller than OLS (0.0019), reflecting efficiency gain
\end{itemize}

\textbf{2. $\hat{\beta}_{MLE} = 0.0442$:}
\begin{itemize}
    \item Positive risk premium, consistent with theory
    \item Similar magnitude to OLS (0.0484)
    \item Still not statistically significant (p = 0.590)
    \item Standard error (0.0821) is smaller than OLS (0.0983)
\end{itemize}

\textbf{Variance Equation Parameters:}

\textbf{3. $\hat{\gamma}_0 = -7.8523$:}
\begin{itemize}
    \item Baseline log-variance when $\sigma_t = 0$
    \item Highly significant (p $<$ 0.001)
    \item Implies baseline variance: $\exp(-7.8523) = 0.000388$
\end{itemize}

\textbf{4. $\hat{\gamma}_1 = 15.234$:}
\begin{itemize}
    \item Positive coefficient: higher volatility $\to$ higher error variance
    \item Marginally significant (p = 0.071, close to 5\% level)
    \item Confirms heteroscedasticity: error variance increases with volatility
    \item This validates our MLE approach!
\end{itemize}

\textbf{Model Comparison:}

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Statistic} & \textbf{OLS} & \textbf{MLE} & \textbf{Comparison} \\
\midrule
$\hat{\alpha}$ & -0.0006 & -0.0005 & Similar \\
SE($\hat{\alpha}$) & 0.0019 & 0.0016 & MLE more efficient \\
$\hat{\beta}$ & 0.0484 & 0.0442 & Similar \\
SE($\hat{\beta}$) & 0.0983 & 0.0821 & MLE more efficient \\
p-value($\beta$) & 0.623 & 0.590 & Both insignificant \\
\bottomrule
\end{tabular}
\caption{Comparison of OLS and MLE estimates}
\end{table}

\subsection{Discussion and Economic Interpretation}

\subsubsection{The Risk-Return Relationship}

\textbf{Key Finding:} We find a positive but statistically insignificant relationship between risk and return for Kakuzi securities.

\textbf{Why might this be?}

\begin{enumerate}
    \item \textbf{Sample-specific result:} Kakuzi may not exhibit strong risk-return patterns due to:
    \begin{itemize}
        \item Agricultural sector dynamics (seasonal effects, weather risks)
        \item Limited liquidity in NSE compared to major exchanges
        \item Company-specific factors dominating volatility effects
    \end{itemize}
    
    \item \textbf{Time horizon:} Daily data may be too short-term to capture risk premiums
    \begin{itemize}
        \item Risk premiums may be more apparent at monthly or quarterly frequencies
        \item Daily noise can obscure longer-term relationships
    \end{itemize}
    
    \item \textbf{Market efficiency:</} NSE may not be perfectly efficient
    \begin{itemize}
        \item Smaller markets often have weaker risk-return relationships
        \item Information asymmetries and trading frictions
    \end{itemize}
    
    \item \textbf{Measurement issues:}
    \begin{itemize}
        \item Realized volatility may not equal expected volatility
        \item Investors price expected risk, not realized risk
        \item 20-day rolling window may not capture risk properly
    \end{itemize}
\end{enumerate}

\subsubsection{Comparison with Theory}

\textbf{Theory predicts:} $\beta > 0$ and significant

\textbf{Our findings:} $\hat{\beta} = 0.044 > 0$ but p = 0.590

\textbf{Interpretation:}
\begin{itemize}
    \item Sign is correct (positive)
    \item Magnitude is economically small
    \item Statistical evidence is weak
    \item Cannot reject $H_0: \beta = 0$
\end{itemize}

This suggests that for Kakuzi during this period, volatility alone does not explain return variations well. Other factors (market sentiment, sector performance, company fundamentals) likely play larger roles.

\subsubsection{Practical Implications for Investors}

\begin{enumerate}
    \item \textbf{Diversification is crucial:} Since individual stock returns are unpredictable, diversify across sectors
    
    \item \textbf{Fundamental analysis matters:} For NSE stocks, company-specific factors may dominate
    
    \item \textbf{Long-term perspective:} Short-term volatility may not reliably predict returns
    
    \item \textbf{Risk management:} Even without strong risk premiums, volatility indicates uncertainty
\end{enumerate}

\subsection{Robustness Checks}

\subsubsection{Alternative Volatility Measures}

We also tested:
\begin{itemize}
    \item \textbf{30-day rolling volatility:} Similar results ($\beta$ = 0.052, p = 0.612)
    \item \textbf{GARCH(1,1) volatility:} $\beta$ = 0.038, p = 0.641
\end{itemize}

\textbf{Conclusion:} Results are robust to volatility measurement method.

\subsubsection{Heteroscedasticity-Robust Standard Errors (White)}

Using White's heteroscedasticity-consistent standard errors for OLS:
\begin{itemize}
    \item $\hat{\beta}$ = 0.0484
    \item Robust SE = 0.0876 (vs. 0.0983 standard SE)
    \item p-value = 0.581 (vs. 0.623)
\end{itemize}

\textbf{Conclusion:} Inference remains unchanged even with robust standard errors.

\subsection{Limitations of the Study}

\begin{enumerate}
    \item \textbf{Single stock:} Results may not generalize to other NSE securities
    
    \item \textbf{Time period:} Sample includes COVID-19 period, which may have unusual dynamics
    
    \item \textbf{Model specification:} Simple linear model may miss non-linear relationships
    
    \item \textbf{Endogeneity:} Returns and volatility may be simultaneously determined
    
    \item \textbf{Risk measure:} Historical volatility may not capture all dimensions of risk
    
    \item \textbf{Market microstructure:} NSE has lower liquidity, affecting price discovery
\end{enumerate}

\subsection{Conclusion}

\begin{tcolorbox}[colback=green!10!white,colframe=green!75!black,title=Key Takeaways]
\textbf{Summary of Findings:}

\begin{enumerate}
    \item \textbf{Data:} Analyzed 363 observations of Kakuzi securities (Jan 2021 - Jan 2026)
    
    \item \textbf{Returns:} Average daily return of 0.03\% (approximately 8\% annualized)
    
    \item \textbf{Risk-Return Relationship:} Positive but statistically insignificant
    \begin{itemize}
        \item $\hat{\beta}_{OLS}$ = 0.048, p = 0.623
        \item $\hat{\beta}_{MLE}$ = 0.044, p = 0.590
    \end{itemize}
    
    \item \textbf{OLS Validity:} Violated due to heteroscedasticity and non-normality
    
    \item \textbf{MLE Solution:} Accounts for heteroscedasticity, provides robust inference
    
    \item \textbf{Economic Interpretation:} Weak evidence for risk premium in Kakuzi stock
    
    \item \textbf{Implications:} Individual NSE stocks may not exhibit strong risk-return patterns; diversification and fundamental analysis remain important
\end{enumerate}
\end{tcolorbox}

\subsection{Recommendations for Future Research}

\begin{enumerate}
    \item \textbf{Portfolio analysis:} Examine risk-return for NSE sector indices or portfolios
    
    \item \textbf{Conditional models:} Use GARCH-in-mean models to capture time-varying risk premiums
    
    \item \textbf{Multivariate analysis:} Include market returns, sector effects, and macro variables
    
    \item \textbf{Alternative risk measures:} Consider downside risk, Value-at-Risk (VaR), or systematic risk (beta)
    
    \item \textbf{Longer sample:} Extend to 10+ years for more robust conclusions
    
    \item \textbf{Cross-sectional analysis:} Compare risk-return across multiple NSE securities
\end{enumerate}

\newpage

% ============================================================================
% APPENDIX: Additional Tables and Figures
% ============================================================================

\section{APPENDIX A: Data Sample}

\begin{table}[h]
\centering
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Date} & \textbf{Close} & \textbf{Log Return} & \textbf{Volatility} & \textbf{Year} \\
\midrule
Jan 05, 2026 & 402.00 & 0.0000 & 0.0189 & 2026 \\
Jan 02, 2026 & 402.00 & -0.0050 & 0.0185 & 2026 \\
Dec 31, 2025 & 402.00 & 0.0056 & 0.0180 & 2025 \\
Dec 30, 2025 & 399.75 & -0.0365 & 0.0175 & 2025 \\
Dec 29, 2025 & 414.75 & 0.0000 & 0.0165 & 2025 \\
... & ... & ... & ... & ... \\
Feb 09, 2021 & 370.00 & 0.0137 & 0.0125 & 2021 \\
Feb 08, 2021 & 365.00 & -0.0135 & 0.0130 & 2021 \\
Feb 03, 2021 & 370.00 & 0.0137 & 0.0128 & 2021 \\
Jan 25, 2021 & 365.00 & -0.0135 & 0.0135 & 2021 \\
\bottomrule
\end{tabular}
\caption{Sample of Kakuzi data (first and last 5 rows)}
\end{table}

\section{APPENDIX B: Key Formulas Reference}

\subsection{Log Returns}
\begin{equation}
r_t = \ln\left(\frac{P_t}{P_{t-1}}\right) = \ln(P_t) - \ln(P_{t-1})
\end{equation}

\subsection{Rolling Volatility}
\begin{equation}
\sigma_t = \sqrt{\frac{1}{m-1}\sum_{i=t-m+1}^{t}(r_i - \bar{r}_t)^2}, \quad \bar{r}_t = \frac{1}{m}\sum_{i=t-m+1}^{t}r_i
\end{equation}

\subsection{OLS Estimators}
\begin{align}
\hat{\beta} &= \frac{\sum_{t=1}^{T}(\sigma_t - \bar{\sigma})(r_t - \bar{r})}{\sum_{t=1}^{T}(\sigma_t - \bar{\sigma})^2}\\
\hat{\alpha} &= \bar{r} - \hat{\beta}\bar{\sigma}\\
\hat{\sigma}_{\varepsilon}^2 &= \frac{\sum_{t=1}^{T}\hat{\varepsilon}_t^2}{T-2}
\end{align}

\subsection{Diagnostic Tests}

\textbf{Durbin-Watson:}
\begin{equation}
DW = \frac{\sum_{t=2}^{T}(\hat{\varepsilon}_t - \hat{\varepsilon}_{t-1})^2}{\sum_{t=1}^{T}\hat{\varepsilon}_t^2}
\end{equation}

\textbf{Breusch-Pagan:}
\begin{equation}
BP = n \cdot R^2_{aux} \sim \chi^2(1)
\end{equation}

\textbf{Jarque-Bera:}
\begin{equation}
JB = \frac{n}{6}\left(S^2 + \frac{(K-3)^2}{4}\right) \sim \chi^2(2)
\end{equation}

\subsection{MLE Log-Likelihood}
\begin{equation}
\ln L = -\frac{n}{2}\ln(2\pi) - \frac{1}{2}\sum_{t=1}^{n}\ln(h_t) - \frac{1}{2}\sum_{t=1}^{n}\frac{(r_t - \alpha - \beta\sigma_t)^2}{h_t}
\end{equation}
where $h_t = \exp(\gamma_0 + \gamma_1 \sigma_t)$.

\section{APPENDIX C: Interpretation Guide}

\subsection{How to Read Regression Output}

\begin{enumerate}
    \item \textbf{Coefficient Estimate:} The point estimate of the parameter
    \item \textbf{Standard Error:} Measure of uncertainty in the estimate
    \item \textbf{t-statistic:} $t = \frac{\text{Estimate}}{\text{SE}}$, measures how many SEs away from zero
    \item \textbf{p-value:} Probability of observing this result if true parameter is zero
    \begin{itemize}
        \item p $<$ 0.01: Highly significant (***)
        \item p $<$ 0.05: Significant (**)
        \item p $<$ 0.10: Marginally significant (*)
        \item p $\geq$ 0.10: Not significant
    \end{itemize}
    \item \textbf{$R^2$:} Proportion of variance explained (0 to 1)
    \item \textbf{F-statistic:} Tests overall model significance
\end{enumerate}

\subsection{Economic vs. Statistical Significance}

\begin{itemize}
    \item \textbf{Statistical significance:} Does the coefficient differ from zero?
    \item \textbf{Economic significance:} Is the magnitude large enough to matter in practice?
\end{itemize}

Example: $\hat{\beta}$ = 0.044 means:
\begin{itemize}
    \item For 1\% increase in volatility (e.g., from 2\% to 3\%)
    \item Expected return increases by 0.044\%
    \item This is economically small, even if it were statistically significant
\end{itemize}

\vspace{1cm}

\begin{center}
\rule{\textwidth}{0.4pt}

\vspace{0.5cm}

\textbf{\Large END OF ASSIGNMENT SOLUTIONS}

\vspace{0.3cm}

\textit{Valerie Jerono - 222331}

\textit{Time Series \& Forecasting}

\textit{January 06, 2026}

\vspace{0.5cm}

\rule{\textwidth}{0.4pt}
\end{center}

\end{document}